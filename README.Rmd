---
title: "Analysis of Water Temperature Trends Using GAM & ARIMA Models"
subtitle: "A Collaboration with STINAPA"
author: "Tadge McWilliams"
date: "August 13th, 2023"
output: 
  html_document:
    toc: TRUE
    toc_float:
      collapsed: FALSE
---


```{r global settings, setup, include=FALSE}
library(knitr) #global settings
opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```


```{r loading packages}
library(readxl)
library(tidyverse) 
library(lubridate) # for dates
library(pander) # for tables
library(flextable) #for nice table
library(rempsyc) #for nice table
library(astsa) #for time series modeling and plotting
library(imputeTS) #for imputing missing time series data
library(forecast) #for auto.arima
library(mgcv) #for gam modeling

```


```{r loading data}
setwd("~/Documents/Data Science/STINAPA/Temp & Light Project")
tl2020 <- read_excel("2020 raw.xlsx", sheet = 1)
tl2021 <- read_excel("2021 raw.xlsx", sheet = 1)
tl2022 <- read_excel("2022 raw.xlsx", sheet = 1)
```

![](/Users/tadgemcwilliams/Documents/Data Science/STINAPA/STINAPA/Joanne's Sunchi1.jpg)

## Summary

The documented effects of climate change have the potential to alter the underwater ecosystem in considerable ways.   Rapid increases in temperature can damage reef systems, alter fish migration patterns, and disrupt food chains.  
The goal of this project is to assist [Stichting Nationale Parken Bonaire](https://stinapabonaire.org) (STINAPA) in their review and analysis of water temperature data collected around Bonaire between 2020 and 2022.  Special consideration is given to temperature outliers.  Values deemed to be impossible water temperatures have been removed while low temperature outliers have been retained.  Missing data has been interpolated using seasonally decomposed imputation.  The resulting data set is used to develop an Autoregressive Integrated Moving Average (ARIMA) model and Generalized Additive Model (GAM) by which to generate seasonal temperature predictions with confidence intervals.  While more analysis is needed, this project is intended to encourage additional analysis of temperature shifts and the development of future models from which STINAPA and others can further their work.

## Methodology

This analysis is based on a series of aggregations and transformations of the data provided.  All calculations and visualizations are performed using R. R packages for this project include *knitr*, *readxl*, *tidyverse*, *lubridate*, *flextable*, *rempsyc*, *asta*, *imputeTS*, *forecast*, and *mgcv*. The report is formatted in Markdown, and all versions have been pushed to a GitHub repository.

### Data Collection

The data provided was collected during 2020 through 2022 by STINAPA using HOBO temperature and light data loggers.  Data loggers were place in four locations and at three depths per location.  Each data logger recorded a temperature observation every five minutes.  Each weeks, data was collected and the HOBO data loggers were cleaned by STINAPA. In total, there are **1,932,026 observations**.  Each observation was recorded with the following variables:

* **date:** Date observation was collected (Y-M-D).
* **time:** Time observation was collected (H-M-S).
* **temp_c:** Temperature recorded in Celsius.
* **sensor_id:** Serial number of HOBO data logger. 
* **site:** Location of data logger.
* **depth_m:** The depth of the data logger in meters.


### Data Cleaning

Outliers play an important part in this data set.  Statistically, outliers are observations that fall beyond the upper and lower quartiles by at least 1.5 times the interquartile range. While outliers can represent collection errors, they can also represent real environmental anomalies that lead to new discoveries or help to explain a greater trend in the data.  For these reasons, I have used a conservative approach in handling outliers.

For this data set I chose to include all observations below the first quartile.  My reasoning is as follows: First, it is reasonable to assume that abnormally low temperature readings are legitimate.  Given Bonaire's hot climate, unnatural readings are difficult to produce unless a data logger malfunctions or is placed in an artificially cooled environment.  Secondly, upwellings of colder water have been recorded in the past, and these upwellings can have a significant effect on the environment.  Thus, their presence is an important feature for study.

Outliers above the third quartile were carefully considered.  In reviewing the data, it is clear that some temperature readings are impossible ocean temperatures.  There is also a plausible scenario in which the data loggers continued to record temperatures when they were brought above water.  They were likely placed on a boat in direct sunlight during weekly cleaning and data retrieval.  I concluded that the impossible values should be removed from the data set so as to yield a more accurate analysis, but choosing a threshold for unnatural observations was challenging.  Initially, I calculated the the threshold using a standard statistical outlier method (Q3 + 1.5 x IQR) for each year; however, a significant number of observations fall along that threshold.  Additionally, the data appears to have a bi-modal distribution due to seasonal weather patterns.  Using an outlier threshold of 1.5 x IQR is typically only an acceptable practice with normally distributed data.

In consulting Erik Meesters, Tropical Marine Ecologist and Bio Statistician at Wageningen Marine Research, I agreed with his direction that any observations above 33 degrees Celsius were not recorded in the water[^1].  The visualizations below help to confirm that while a 33-degree threshold is made a priori, the greater threshold includes potentially natural outliers while excluding the majority of observations that are impossible for the climate.  This method could be deemed overly conservative or simplistic, but as Mr. Meesters aptly suggested, it would be prudent not to omit any observations unless you are 100% sure the reading is wrong.

[^1]: E. Meesters, personal communication, March 16th, 2023.

```{r 2020 outliers}

quant2020 <- quantile(tl2020$temp_c, probs = c(0.25, 0.75))
statoutlier2020 <- (IQR(tl2020$temp_c) * 1.5) + quant2020[2]

ggplot(tl2020, aes(x=factor(month(date)), y = temp_c)) + 
    stat_boxplot(geom ='errorbar', width = 0.2) + 
    geom_boxplot() +
    xlab("Month") + 
    ylab("Water Temperature (c)") +
    ggtitle("2020 Temperature Variations") +
    geom_hline(aes(yintercept = 33, col = "33 Degrees")) + 
    geom_hline(aes(yintercept = statoutlier2020, col = "1.5 x IQR")) +
    theme(legend.title=element_blank())

```


```{r 2021 outliers}
#ggplot(tl2021, aes(temp_c)) +
#  geom_bar(width = 0.1) + 
#  facet_wrap(~depth_m) +
#  xlab("Temperature (c)") +
#  ylab("Data Points") +
#  ggtitle("2021 Distribution by Sensor Depth (m)")

quant2021 <- quantile(tl2021$temp_c, probs = c(0.25, 0.75))
statoutlier2021 <- (IQR(tl2021$temp_c) * 1.5) + quant2021[2]

ggplot(tl2021, aes(x=factor(month(date)), y = temp_c)) + 
    stat_boxplot(geom ='errorbar', width = 0.2) + 
    geom_boxplot() +
    xlab("Month") + 
    ylab("Water Temperature (c)") +
    ggtitle("2021 Temperature Variations") +
    geom_hline(aes(yintercept = 33, col = "33 Degrees")) + 
    geom_hline(aes(yintercept = statoutlier2021, col = "1.5 x IQR")) +
    theme(legend.title=element_blank())
```


```{r 2022 outliers}
#ggplot(tl2022, aes(temp_c)) +
#  geom_bar(width = 0.1) + 
#  facet_wrap(~depth_m) +
#  xlab("Temperature (c)") +
#  ylab("Data Points") +
#  ggtitle("2022 Distribution by Sensor Depth (m)")

quant2022 <- quantile(tl2022$temp_c, probs = c(0.25, 0.75))
statoutlier2022 <- (IQR(tl2022$temp_c) * 1.5) + quant2022[2]

ggplot(tl2022, aes(x=factor(month(date)), y = temp_c)) + 
    stat_boxplot(geom ='errorbar', width = 0.2) + 
    geom_boxplot() +
    xlab("Month") + 
    ylab("Water Temperature (c)") +
    ggtitle("2022 Temperature Variations") +
    geom_hline(aes(yintercept = 33, col = "33 Degrees")) + 
    geom_hline(aes(yintercept = statoutlier2022, col = "1.5 x IQR")) +
    theme(legend.title=element_blank())
```

```{r removing outliers above 33 degrees}
tl2020_33 <- tl2020 %>% filter(temp_c <= 33)
tl2021_33 <- tl2021 %>% filter(temp_c <= 33)
tl2022_33 <- tl2022 %>% filter(temp_c <= 33)
```


```{r formatting date and time columns}
tl2020_33$date <- as.Date(tl2020_33$date)
tl2020_33$time <- strftime(tl2020_33$time, format="%H:%M:%S")

tl2021_33$date <- as.Date(tl2021_33$date)
tl2021_33$time <- strftime(tl2021_33$time, format="%H:%M:%S")

tl2022_33$date <- as.Date(tl2022_33$date)
tl2022_33$time <- strftime(tl2022_33$time, format="%H:%M:%S")
```


## Data Analysis

### Summary Statistics

I aggregated the data by date, then filtered for the daily minimum, maximum, and average temperatures.  From 2020 through 2022, there is an increase in the temperature difference between the monthly high-temperature and the monthly mean.  Average temperatures during 2021 were lower in many months than in 2020 or 2022.  Review of average temperatures by depth indicate a significant decrease in temperature at six meters during 2021 and a greater spread between depths in 2022.  

```{r daily min/max and avg water temp by day}
# 2020
temp20mm <- tl2020_33 %>% 
  select(date, site, depth_m, temp_c) %>%
  group_by(site, depth_m, date) %>% 
  summarise(min_temp = min(temp_c),
            avg_temp = mean(temp_c),
            max_temp = max(temp_c)) %>%
  arrange(date, site, depth_m)

# 2021
temp21mm <- tl2021_33 %>% 
  select(date, site, depth_m, temp_c) %>%
  group_by(site, depth_m, date) %>% 
  summarise(min_temp = min(temp_c),
            avg_temp = mean(temp_c),
            max_temp = max(temp_c)) %>%
  arrange(date, site, depth_m)

# 2022
temp22mm <- tl2022_33 %>% 
  select(date, site, depth_m, temp_c) %>%
  group_by(site, depth_m, date) %>% 
  summarise(min_temp = min(temp_c),
            avg_temp = mean(temp_c),
            max_temp = max(temp_c)) %>%
  arrange(date, site, depth_m)

# Combine all years
temp_mma <- temp20mm %>%
  bind_rows(temp21mm) %>%
  bind_rows(temp22mm) %>%
  mutate(year = year(date),
         month = month(date))

# 2020 summary stats
temp_mma %>% 
  filter(year == 2020) %>%
  group_by(factor(months(date), level = month.name)) %>%
  summarize(min.temp = round(min(min_temp),2),
            avg.temp = round(mean(avg_temp),2),
            max.temp = round(max(max_temp),2),
            range = round(max.temp - min.temp, 2),
            high_above_avg = round(max.temp - avg.temp, 2)) %>%
  rename("Month" = "factor(months(date), level = month.name)",
         "Minimum" = min.temp,
         "Mean" = avg.temp,
         "Maximum" = max.temp,
         "Range" = range,
         "Max From Mean" = high_above_avg) %>%
  nice_table(title = "2020 Temperature Summary Statistics") %>%
  colformat_num(digits = 1)

# 2021 summary stats
temp_mma %>% 
  filter(year == 2021) %>%
  group_by(factor(months(date), level = month.name)) %>%
  summarize(min.temp = round(min(min_temp),2),
            avg.temp = round(mean(avg_temp),2),
            max.temp = round(max(max_temp),2),
            range = round(max.temp - min.temp, 2),
            high_above_avg = round(max.temp - avg.temp, 2)) %>%
  rename("Month" = "factor(months(date), level = month.name)",
         "Minimum" = min.temp,
         "Mean" = avg.temp,
         "Maximum" = max.temp,
         "Range" = range,
         "Max From Mean" = high_above_avg) %>%
  nice_table(title = "2021 Temperature Summary Statistics") %>%
  colformat_num(digits = 1)

# 2022 summary stats
temp_mma %>% 
  filter(year == 2022) %>%
  group_by(factor(months(date), level = month.name)) %>%
  summarize(min.temp = round(min(min_temp),2),
            avg.temp = round(mean(avg_temp),2),
            max.temp = round(max(max_temp),2),
            range = round(max.temp - min.temp, 2),
            high_above_avg = round(max.temp - avg.temp, 2)) %>%
  rename("Month" = "factor(months(date), level = month.name)",
         "Minimum" = min.temp,
         "Mean" = avg.temp,
         "Maximum" = max.temp,
         "Range" = range,
         "Max From Mean" = high_above_avg) %>%
  nice_table(title = "2022 Temperature Summary Statistics") %>%
  colformat_num(digits = 1)

```



```{r visualizing general temperature trends}
ggplot(temp_mma, aes(month,  avg_temp, color = factor(year))) +
  geom_smooth(se=FALSE, span = 0.05) +
  scale_color_manual(name = "Year", 
                       labels = c("2020", "2021", "2022"),
                       values = c("deepskyblue1","darkviolet","darkblue"),
                       guide = guide_legend(reverse = TRUE)) +
    scale_x_continuous(breaks = 1:12) + 
    labs(x = "Month", y = "Temperature (c)") +
    ggtitle("Average Water Temperature by Year") 


ggplot(temp_mma, aes(date, avg_temp, color = factor(depth_m))) +
  geom_smooth(se=FALSE) +
  labs(x = "Year",
       y = "Temperature (c)",
       color = "Depth (m)",
       title = "Average Water Temperature by Depth")

ggplot(temp_mma, aes(factor(depth_m), avg_temp, color = site)) +
  geom_boxplot() +
  labs(x = "Depth (m)",
       y = "Temperature (c)",
       color = "Site",
       title = "Average Water Temperature by Depth & Location")
```


Below is a summary of the data collected by location.  Of all the sites, STINAPA collected the most data from Klein Bonaire 1.  Of all the depths, the most data was collected at 12 meters.  Finally, the most data collected for a specific location (site and depth) was from Klein Bonaire 1 at 20 meters.

The histogram indicates that the data is multi-modal.  This is logical as the observations reflect seasonal data.  Changes between summer and winter create a multi-modal distribution of temperatures.  


```{r reviewing data by site and depth}

pander(table(temp_mma$site, temp_mma$depth_m))
pander(table(temp_mma$site, temp_mma$depth_m) %>% rowSums())
pander(table(temp_mma$site, temp_mma$depth_m) %>% colSums())


temp_mma %>% filter(depth_m == 12) %>%
  ggplot(aes(avg_temp, fill = site)) +
  geom_histogram(binwidth = 0.1) +
  facet_wrap(vars(site)) + 
  labs(x = "Temperature (c)", 
       y = "Observations",
       fill = "Site",
       title = "Observations Collected by Temperature & Location")

```

### Low Temperature Outliers

The plots above indicate a number of observations with temperatures below the first quartile.  The tables below list the lowest temperature observations for each year. It is notable that the isolated low temperature events in 2022 were all recorded at six meters.  No significant low temperatures were recorded at lower depths.  

```{r review of low outliers}

# 2020 low temp outliers
temp20mm %>% filter(min_temp < 23) %>% arrange(date)  %>%
  rename("Date" = date, 
         "Site" = site, 
         "Depth (m)" = depth_m, 
         "Minimum" = min_temp, 
         "Average" = avg_temp,
         "Maximum" = max_temp) %>%
  nice_table(title = "2020 Temperature Observations Below 23 Degrees (c)")

# 2021 low temp outliers
temp21mm %>% filter(min_temp < 23) %>% arrange(date)  %>%
  rename("Date" = date, 
         "Site" = site, 
         "Depth (m)" = depth_m, 
         "Minimum" = min_temp, 
         "Average" = avg_temp,
         "Maximum" = max_temp) %>%
  nice_table(title = "2021 Temperature Observations Below 23 Degrees (c)")
            
# 2022 low temp outliers
temp22mm %>% filter(min_temp < 23) %>% arrange(date)  %>%
  rename("Date" = date, 
         "Site" = site, 
         "Depth (m)" = depth_m, 
         "Minimum" = min_temp, 
         "Average" = avg_temp,
         "Maximum" = max_temp) %>%
  nice_table(title = "2022 Temperature Observations Below 23 Degrees (c)")

```

## Model Developement

I made the decision to use the data collected from 20 meters for the time series model.  By isolating the model to one depth, I intend to create a more accurate model than if I were to assume all the data follow one trend, regardless of depth.  

Below is the distribution of temperatures.  Once the maximum, average, and minimum temperatures are separated, a clear bi-modal distribution is visible.  Variation in the QQ-Plot also confirms the data is not normally distributed.  

Future modeling must include a seasonality component to account for the distribution. 

```{r model prep- filtering to 12m}
# Filtering 12 meters from all sites, then averaging each day's data.
temp_20m <- temp_mma %>% 
  filter(depth_m == 20) %>%
  group_by(date)

# Filtering for dates and average temps.
avgTemp20m <- temp_20m %>%
  summarize(avg_temp = mean(avg_temp)) %>%
  arrange(date)

# Plotting distribution of stats.
temp_20m %>% pivot_longer('min_temp':'max_temp', 
                          names_to = "stat", 
                          values_to = "value") %>%
  ggplot(aes(value, fill = stat)) +
    geom_histogram(binwidth = 0.1, 
                   alpha = 0.5, 
                   position = "identity") +
    scale_fill_discrete(labels = c("Average", "Maximum", "Minimum")) +
    labs(x = "Temperature (c)", 
         y = "Observations", 
         fill = "Daily Temperature",
         title = "Distribution of Temperatures at 20 Meters") +
    theme(legend.position = c(0.85, 0.8))

# QQ plot.  
qqnorm(avgTemp20m$avg_temp, main = "QQ-plot")
qqline(avgTemp20m$avg_temp, col = "red")
```
### Missing Data

An important factor in time series analysis is the continuity of time.  Using the *statNA* function from the *imputeTS* package, I determine that 220 observations (days) are missing from the timeline.  This represents a significant proportion of the data set (22%).  
The plots below indicate that the data is missing at random.  Imputation must be used to complete the data set as reducing its length would not yield a complete year by which to model seasonal trends.

```{r modeling prep for NAs}

# Populating complete date series
avgTemp20_full <- avgTemp20m %>%
  mutate(date = as.Date(date)) %>%
  complete(date = seq.Date(min(date), max(date), by="day"))


# Reviewing NAs by missing days.
statsNA(avgTemp20_full$avg_temp)

```


In order to minimize the amount of imputation needed, I aggregate the data into weekly temperature averages.  This reduces the percentage of missing data to 15.2% (22 weeks).  Additionally, the weekly averages yield a more manageable data set for seasonal differencing.  Below is a plot of missing data by week.

```{r Modeling Prep- Aggregating into weekly data}

# Aggregating into weekly averages to minimize imputation needs.
avgTemp20_full <- avgTemp20_full %>% 
  mutate(week = week(date),
         year = year(date))

avgTemp20_weekly <- avgTemp20_full %>% 
  select(year, week, avg_temp) %>%
  group_by(year, week) %>%
  mutate(wk_temp = mean(avg_temp, na.rm=TRUE)) %>%
  distinct(year, week, wk_temp)

# Validating all weeks are present.
# table(avgTemp20_weekly$year, avgTemp20_weekly$week)

# Reviewing missing data from weekly averages.
statsNA(avgTemp20_weekly$wk_temp)

ggplot_na_distribution(avgTemp20_weekly$wk_temp) +
  labs(x="Weeks", y="Temperature (c)", subtitle = "Weekly averages with highlighted missing regions")
```

### Imputation

There are various imputation strategies.  The use of random, mean, or last-observed-carried-forward imputation were ruled out due to the seasonal nature of the data.  Seasonally Split, and Seasonally Decomposed imputation methods are provided below.  

The Seasonally Split method separates the data into seasons before imputing missing values for each season.  This method adds dimension, but it is apparent that some imputations are based on micro trends of adjacent years and diverge from the seasonal slope.  The Seasonally Decomposed imputation method removes the seasonal trends of the data set, imputes values based on the de-trended static time series, then reintroduces the seasonal trends.  When applied to the data set, this method applies dimensionality while following a more direct slope between known values than the seasonal split method.  Therefore, I selected Seasonally Decomposed imputation for this model.


```{r model prep, imputing missing values}

#kalman <- na_kalman(timeseries, model = "auto.arima")
#locf <- na_locf(timeseries, na_remaining = "rev")
#ma <- na_ma(timeseries, k=4, weighting="exponential")
#interpolation <- na_interpolation(timeseries, option = "linear")
seasplit <- na_seasplit(avgTemp20_weekly$wk_temp, algorithm = "ma", find_frequency = TRUE)
seadec <- na_seadec(avgTemp20_weekly$wk_temp, algorithm = "interpolation", find_frequency = TRUE)

#ggplot_na_imputations(timeseries, kalman)
#ggplot_na_imputations(timeseries, locf)
#ggplot_na_imputations(timeseries, ma)
#ggplot_na_imputations(timeseries,interpolation, title = "Linear Interpolation")
ggplot_na_imputations(avgTemp20_weekly$wk_temp, seasplit, title = "Seasonally Split Interpolation")
ggplot_na_imputations(avgTemp20_weekly$wk_temp, seadec, title = "Seasonally Decomposed Interpolation")

ts_complete <- ts(seadec)
```

### ARIMA Model Development

To model time series trends I use an Autoregressive Integrated Moving Average (ARIMA) model. After differencing the time series with a 52-week lag to remove trends, I apply an auto-correlation function to view correlation coefficients by time series lag.  The tailing ACF and drop-off in Partial ACF suggest that the ARIMA model should include a autoregressive component.  The presence of the significant Partial ACF coefficient at lag 12 suggests that the model should also include a moving average component.

```{r time series model 1}

# Ploting time series and de-trended time series.
par(mfrow = c(3,1))
plot(ts_complete)
plot(diff(ts_complete, lag = 52))
plot(diff(diff(ts_complete, lag = 52)))

# Plotting auto correlation and partial auto correlation.
ts_complete %>% diff(lag=52) %>% acf2(max.lag = 52)

```


I calculate a basic ARIMA model using the *auto.arima* function.  In agreement with the ACF calculations, the suggested model is an ARIMA(2,0,1) model with two autoregressive components and one moving average component.  The p-value for all components is zero.  The plot also suggests that the residual values follow a white noise pattern, indicating a good fit.

Surprisingly, the *auto.arima* function did not return a seasonal component.  Below the ARIMA(2,0,1) results, I manually fit a seasonal ARIMA model (SARIMA) in an effort to improve accuracy.  While a SARIMA(2,0,1)(0,0,1)[26] model yields a similar Akaike's Information Criterion (AIC) score to the ARIMA(2,0,1) model, the ARIMA model is marginally more accurate.  It is possible that annual trends are not significant for this data set due to the number of years included.  Thus, the ARIMA(2,0,1) model is the most accurate for this data set. However, it would be wise to reconsider the SARIMA(2,0,1)(0,0,1)[26] model if the data set were expanded.


```{r arima model tuning}

# Non-seasonal model with auto.arima from forecast package.
auto.arima(ts_complete) 
model <- sarima(ts_complete, p=2, d=0, q=1)

# seasonal model
sarima(ts_complete, p=2,d=0,q=1,P=0,D=0,Q=1,S=26)
```


#### ARIMA Model Predictions

Below, both ARIMA models are trained on 90% of the time series then used to predict the remaining 10% of the known values.  When the estimated values are compared with the actual values, both models appear to fit well.  Additionally, the two models have the same root-mean-square-error (RMSE) and mean-absolute-percentage-error (MAPE) to within one ten-thousandth.


```{r arima model predictions}

# visualizing ARIMA(2,0,1) accuracy.
train  <- window(ts_complete, end = round(length(ts_complete)*0.9, 0)) # 90% of data
test <- window(ts_complete, end = length(ts_complete))
new_values <- 14
pred <- sarima.for(train, n.ahead = new_values, p=2,d=0,q=1, 
                   main="ARIMA(2,0,1) Temperature Predictions",
                   xlab="Weeks")
lines(test)


pander(accuracy(pred$pred, test))


# visualizing accuracy of SARIMA model.
strain  <- window(ts_complete, end = round(length(ts_complete)*0.9, 0)) # 90% of data
stest <- window(ts_complete, end = length(ts_complete))
new_values <- 14
spred <- sarima.for(strain, n.ahead = new_values, p=2,d=0,q=1,P=0,D=0,Q=1,S=26, 
                   main="SARIMA(2,0,1)(0,0,1)[26] Temperature Predictions",
                   xlab="Weeks")
lines(test)

pander(accuracy(spred$pred, test))

```


### GAM Model Development

I selected a Generalize Additive Model (GAM) as an alternative modeling method.  As GAMs are composed of multiple smooth functions, I hoped the approach would yield an accurate non-linear model derived from separate annual, weekly, and daily functions to determine water temperature.  For this model I use the daily averages of water temperatures instead of the weekly averaged data used in the ARIMA models as the GAM results prove to be are more accurate with the added data.  Seasonally Decomposed Interpolation is again used to fill the missing training data.

I use a log transformation and adjust K-values to tune the GAM.  The model summary confirms the results are statistically significant with p-values below 0.001.  The concurvity tests indicate high levels of concurvity between the input variables.  While not optimal for many models, this is common with time smooths that utilize multiple units of measure.  I propose that the benefit of smoothing across annual, weekly, and daily segments outweighs the loss in interpretability as each variable is a unit of time.  

The residual plots do not indicate notable trends, residuals appear to have a Gaussian distribution, and there is a clear linear response.  The GAM residuals are similar in nature with those of the ARIMA models.  The *vis.gam* function provides a tidy visualization of the interaction between the *week* and *year* variables.

```{r GAM train test creation}
# Creating train/test split.
avgTemp20_full$full_temp <- na_seadec(avgTemp20_full$avg_temp, algorithm = "interpolation", find_frequency = TRUE)
ggplot_na_imputations(avgTemp20_full$avg_temp, avgTemp20_full$full_temp, title = "Seasonally Decomposed Interpolation")

split <- round(nrow(avgTemp20_full) * 0.90)
mltrain <- avgTemp20_full[1:split, ]
mltest <- avgTemp20_full[(split + 1) : nrow(avgTemp20_full), ]
```


```{r gam model}

gam.mod <- gam(full_temp ~ s(log(as.numeric(date))) + s(log(week), k=52) + s(log(year), k=3),
               data = mltrain,
               method = "REML") 


summary(gam.mod)
gam.check(gam.mod)

concurvity(gam.mod, full=TRUE)
concurvity(gam.mod, full=FALSE)

checkresiduals(gam.mod)

vis.gam(x=gam.mod, 
        view=c("week", "year"),
        type = "link",
        plot.type = "persp",
        theta = 30)

```

#### GAM Model Predictions

As with the ARIMA models, the GAM was trained on 90% of the data set then used to predict the remaining 10% of known values.  Comparing the estimated values with actual values indicates the model is also a reasonably good fit.  It is notable that the GAM predictions yield a high level of accuracy for the first 10 out of the 14 weeks of predictions before the confidence intervals flair out.  

```{r gam predictions}

gam.pred <- predict(gam.mod, newdata=mltest, se.fit = TRUE)
mltest$gam_preds <- gam.pred$fit
mltest$gam_se <- gam.pred$se.fit

ggplot(avgTemp20_full, aes(x=date, y=full_temp)) +
  geom_point(shape = 1, alpha=0.8) +
  geom_line(alpha=0.3) +
  geom_ribbon(data=mltest,
            aes(date, ymin = gam_preds-gam_se, ymax=gam_preds+gam_se),
            alpha=0.3) +
    geom_point(data=mltest,
            aes(date, gam_preds), 
            shape=1,
            color="red3",
            alpha=0.4) +
    geom_line(data=mltest,
            aes(date, gam_preds), 
            color="red3") +
  scale_y_continuous(limits=c(25.9,31)) +
  labs(x="Date", 
       y="Temperature (c)",
       title="GAM Temperature Predictions") +
  theme_bw()

accuracy(ts(mltest$full_temp), ts(mltest$gam_preds))
```

### Model Comparison

The GAM predictions do not follow as smooth of a predictive line as the ARIMA models; however, the initial few predictions appear to be more accurate.  In comparing the ACF at one lag for each model, the GAM has a higher degree of autocorrelation.  For this test data set the higher ACF does not correspond with a more accurate model, but it does indicate that the GAM is predicting values at a higher correlation with the previous value than the ARIMA models.  For this reason, initial predictions may tend to be more accurate while later predictions may become less so.  In total, the measures of accuracy (RMSE, MAPE, etc.) are lower for the ARIMA models than for the GAM, indicating the ARIMA models are more accurate.  

As with any predictive model, results can be improved through further research, tuning, and testing.  Adjustments to data collection, outlier thresholds, pre-processing, model selection, and hyper-tuning parameters are all relevant areas for improvement.
