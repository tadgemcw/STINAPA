---
title: "Analysis of 2020-2022 Water Temperatures"
subtitle: "A Collaboration with STINAPA"
author: "Tadge McWilliams"
date: "June 8th, 2023"
output: 
  html_document:
    toc: TRUE
    toc_float:
      collapsed: FALSE
---

```{r loading packages, include=FALSE, echo=FALSE}
library(readxl)
library(tidyverse) 
library(lubridate) 
library(flextable) #for nice table
library(rempsyc) #for nice table
library(astsa) #for time series modeling and plotting
```


```{r loading data, echo=FALSE, warning=FALSE}
setwd("~/Documents/Data Science/STINAPA/Temp & Light Project")
tl2020 <- read_excel("2020 raw.xlsx", sheet = 1)
tl2021 <- read_excel("2021 raw.xlsx", sheet = 1)
tl2022 <- read_excel("2022 raw.xlsx", sheet = 1)
```

![](/Users/tadgemcwilliams/Documents/Data Science/STINAPA/STINAPA/Joanne's Sunchi1.jpg)

## Summary
...summary of data, analysis, methods, and findings.

## Data Collected
...highlevel overview of the data collected.  Quantity, sites, depths, locations, missing data.

## Methodology
...how was data handeled. what formuli were used.  what past work was used

### Outliers

Outliers play an important part in this data set.  Statistically, outliers are observations that fall beyond the upper and lower quartiles by at least 1.5 times the interquartile range. While outliers can represent collection errors, they can also represent real environmental anomalies that lead to new discoveries or help to explain a greater trend in the data.  For these reasons, I have used a conservative approach in handling outliers.

For this data set I chose to include all observations below the first quartile.  My reasoning is as follows: First, it is reasonable to assume that abnormally low temperature readings are legitimate.  Given Bonaire's hot climate, unnatural readings are difficult to produce unless the sensor malfunctions or the sensor is placed in an artificially cooled environment.  Second, upwellings of colder water have been recorded in the past, and these upwellings can have a significant effect on the environment.  Thus, their presence is an important feature for study.

Outliers above the third quartile were carefully considered.  In reviewing the data, it is clear that some temperature readings are impossible ocean temperatures.  There is also a plausible scenario in which the data sensors continued to record temperatures when they were brought above water.  They were likely laying on a boat in direct sun during weekly cleaning and data retrieval.  I concluded that the impossible values should be removed from the dataset so as to yield a more accurate analysis, but choosing a threshold for unnatural observations was challenging.  Initially, I calculated the the threshold using a standard statistical outlier method (Q3 + 1.5 x IQR) for each year; however, a significant number of observations fall along that temperature.  Additionally, the data appears to have a multi-modal distribution.  This is likely due to seasonal weather patterns.  Setting a outlier threshold of 1.5 x IQR is typically only an acceptable practice with normally distributed data.

After consulting Erik Meesters, Tropical Marine Ecologist and Bio Statistician at Wageningen Marine Research, I agreed with his suggestion that any observations above 33 degrees celsius were not recorded in the water[^1].  The visualizations below help to confirm that while a 33 degree threshold is somewhat arbitrary, this higher threshold includes potentially natural outliers while excluding the majority of observations that are impossible for the climate.  This method could be deemed overly conservative or simplistic, but as Erik aptly suggested, it would be prudent not to omit any observations unless you are 100% sure the reading is wrong.

[^1]: E. Meesters, personal communication, March 16th, 2023.

```{r 2020 outliers, echo=FALSE, warning=FALSE}
ggplot(tl2020, aes(temp_c)) +
  geom_bar(width = 0.1) + 
  facet_wrap(~depth_m) +
  xlab("Temperature (c)") +
  ylab("Observations") +
  ggtitle("2020 Distribution by Sensor Depth (m)")

quant2020 <- quantile(tl2020$temp_c, probs = c(0.25, 0.75))
statoutlier2020 <- (IQR(tl2020$temp_c) * 1.5) + quant2020[2]

ggplot(tl2020, aes(x=factor(month(date)), y = temp_c)) + 
    stat_boxplot(geom ='errorbar', width = 0.2) + 
    geom_boxplot() +
    xlab("Month") + 
    ylab("Water Temperature (c)") +
    ggtitle("2020 Temperature Variations") +
    geom_hline(aes(yintercept = 33, col = "33 Degrees")) + 
    geom_hline(aes(yintercept = statoutlier2020, col = "1.5 x IQR")) +
    theme(legend.title=element_blank())
```


```{r 2021 outliers, echo=FALSE, warning=FALSE}
ggplot(tl2021, aes(temp_c)) +
  geom_bar(width = 0.1) + 
  facet_wrap(~depth_m) +
  xlab("Temperature (c)") +
  ylab("Data Points") +
  ggtitle("2021 Distribution by Sensor Depth (m)")

quant2021 <- quantile(tl2021$temp_c, probs = c(0.25, 0.75))
statoutlier2021 <- (IQR(tl2021$temp_c) * 1.5) + quant2021[2]

ggplot(tl2021, aes(x=factor(month(date)), y = temp_c)) + 
    stat_boxplot(geom ='errorbar', width = 0.2) + 
    geom_boxplot() +
    xlab("Month") + 
    ylab("Water Temperature (c)") +
    ggtitle("2021 Temperature Variations") +
    geom_hline(aes(yintercept = 33, col = "33 Degrees")) + 
    geom_hline(aes(yintercept = statoutlier2021, col = "1.5 x IQR")) +
    theme(legend.title=element_blank())
```


```{r 2022 outliers, echo=FALSE, warning=FALSE}
ggplot(tl2022, aes(temp_c)) +
  geom_bar(width = 0.1) + 
  facet_wrap(~depth_m) +
  xlab("Temperature (c)") +
  ylab("Data Points") +
  ggtitle("2022 Distribution by Sensor Depth (m)")

quant2022 <- quantile(tl2022$temp_c, probs = c(0.25, 0.75))
statoutlier2022 <- (IQR(tl2022$temp_c) * 1.5) + quant2022[2]

ggplot(tl2022, aes(x=factor(month(date)), y = temp_c)) + 
    stat_boxplot(geom ='errorbar', width = 0.2) + 
    geom_boxplot() +
    xlab("Month") + 
    ylab("Water Temperature (c)") +
    ggtitle("2022 Temperature Variations") +
    geom_hline(aes(yintercept = 33, col = "33 Degrees")) + 
    geom_hline(aes(yintercept = statoutlier2022, col = "1.5 x IQR")) +
    theme(legend.title=element_blank())
```

```{r removing outliers above 33 degrees, echo=FALSE}
tl2020_33 <- tl2020 %>% filter(temp_c <= 33)
tl2021_33 <- tl2021 %>% filter(temp_c <= 33)
tl2022_33 <- tl2022 %>% filter(temp_c <= 33)
```


```{r formatting date and time columns, echo=FALSE}
tl2020_33$date <- as.Date(tl2020_33$date)
tl2020_33$time <- strftime(tl2020_33$time, format="%H:%M:%S")

tl2021_33$date <- as.Date(tl2021_33$date)
tl2021_33$time <- strftime(tl2021_33$time, format="%H:%M:%S")

tl2022_33$date <- as.Date(tl2022_33$date)
tl2022_33$time <- strftime(tl2022_33$time, format="%H:%M:%S")
```

## EDA?
  Looks at summary stats?
  
## Data Analysis

I aggregated the data by date, then filtered for the daily minimum, maximum, and average temperatures.  
Average temperatures during 2022 were lower in many months in in 2020 or 2021.  ...La Ni$\tilde{n}$a info to back this up???

```{r daily min/max and avg water temp by day, echo=FALSE}
#2020
temp20mm <- tl2020_33 %>% 
  select(date, site, depth_m, temp_c) %>%
  group_by(site, depth_m, date) %>% 
  summarise(min_temp = min(temp_c),
            avg_temp = mean(temp_c),
            max_temp = max(temp_c)) %>%
  arrange(date, site, depth_m)

#2021
temp21mm <- tl2021_33 %>% 
  select(date, site, depth_m, temp_c) %>%
  group_by(site, depth_m, date) %>% 
  summarise(min_temp = min(temp_c),
            avg_temp = mean(temp_c),
            max_temp = max(temp_c)) %>%
  arrange(date, site, depth_m)

#2022
temp22mm <- tl2022_33 %>% 
  select(date, site, depth_m, temp_c) %>%
  group_by(site, depth_m, date) %>% 
  summarise(min_temp = min(temp_c),
            avg_temp = mean(temp_c),
            max_temp = max(temp_c)) %>%
  arrange(date, site, depth_m)

#Combine all years
temp_mma <- temp20mm %>%
  bind_rows(temp21mm) %>%
  bind_rows(temp22mm) %>%
  mutate(year = year(date),
         month = month(date))

```


```{r visualizing general temperature trends, echo=FALSE}
ggplot(temp_mma, aes(month,  avg_temp, color = factor(year))) +
  geom_smooth(se=FALSE, span = 0.05) +
  scale_color_manual(name = "Year", 
                       labels = c("2020", "2021", "2022"),
                       values = c("deepskyblue1","darkviolet","darkblue"),
                       guide = guide_legend(reverse = TRUE)) +
    scale_x_continuous(breaks = 1:12) + 
    labs(x = "Month", y = "Temperature (c)") +
    ggtitle("Average of Water Temperature") 


ggplot(temp_mma, aes(date, avg_temp, color = factor(depth_m))) +
  geom_smooth(se=FALSE) +
  labs(x = "Time",
       y = "Temperature (c)",
       color = "Depth (m)",
       title = "Average Water Temperature")


ggplot(temp_mma, aes(factor(depth_m), avg_temp, color = site)) +
  geom_boxplot() +
  labs(x = "Depth (m)",
       y = "Temperature (c)",
       color = "Site",
       title = "Average Water Temperature")
```


Below is a summary of the data collected by location.  Of all the sites, STINAPA collected the most data from Klein Bonaire 1.  Of all the depths, the most data was collected at 12 meters.  Finally, the most data collected for a specific location (site and depth) was from Klein Bonaire 1 at 20 meters.

The histogram indicates that the data is multi-modal.  Also, no one site appears to be significantly skewed in temperature.  


```{r reviewing data by site and depth, echo=FALSE}

table(temp_mma$site, temp_mma$depth_m) 
table(temp_mma$site, temp_mma$depth_m) %>% rowSums() 
table(temp_mma$site, temp_mma$depth_m) %>% colSums()
### can these be formatted to plotted with nice_table?

temp_mma %>% filter(depth_m == 12) %>%
  ggplot(aes(avg_temp, fill = site)) +
  geom_histogram(binwidth = 0.1) +
  facet_wrap(vars(site)) + 
  labs(x = "Temperature (c)", 
       y = "Observations",
       fill = "Site")
```



Below are tables of the lowest temperatures for each year.  From the *Temperature Variations* plots above, it is apparent that 2020 and 2022 had isolated low temperature events while the recorded temperatures in October 2021 were more graduated.
It is interesting that the isolated low temperature events in 2022 were all recorded at six meters.  No significant low temperatures were recorded at lower depths.  

```{r review of low outliers, echo=FALSE}

# 2020 low temp outliers
temp20mm %>% filter(min_temp < 23) %>% arrange(date)  %>%
  rename("Date" = date, 
         "Site" = site, 
         "Depth (m)" = depth_m, 
         "Minimum" = min_temp, 
         "Average" = avg_temp,
         "Maximum" = max_temp) %>%
  nice_table(title = "2020 Temperature Observations Below 23 Degrees (c)")

#2021 low temp outliers
temp21mm %>% filter(min_temp < 23) %>% arrange(date)  %>%
  rename("Date" = date, 
         "Site" = site, 
         "Depth (m)" = depth_m, 
         "Minimum" = min_temp, 
         "Average" = avg_temp,
         "Maximum" = max_temp) %>%
  nice_table(title = "2021 Temperature Observations Below 23 Degrees (c)")
            
#2022 low temp outliers
temp22mm %>% filter(min_temp < 23) %>% arrange(date)  %>%
  rename("Date" = date, 
         "Site" = site, 
         "Depth (m)" = depth_m, 
         "Minimum" = min_temp, 
         "Average" = avg_temp,
         "Maximum" = max_temp) %>%
  nice_table(title = "2022 Temperature Observations Below 23 Degrees (c)")
```

### Trend Modeling

I made the decision to use the data collected from 12 meters from for my time series model.  By isolating my model to one location and one depth, I hope to create a more accurate model than if I were to assume all the data collected followed the same trend, regardless of depth.  Additionally, the Harbour Village data has few outliers in either direction over the three years of data collection.

Below, is the distribution of temperatures.  Once the maximum, average, and minimum temperatures are separated, a clear bi-modal distribution is visible.    

```{r viz of 12 meter data}
# Below, filtering 12 meters from all sites, then averaging each day's data.
temp_12m <- temp_mma %>% 
  filter(depth_m == 12) %>%
  group_by(date)

# Below, filtering for dates and avg. temps
avgTemp12m <- temp_12m %>%
  summarize(avg_temp = mean(avg_temp)) %>%
  arrange(date)


# Plotting distribution of stats.
temp_12m %>% pivot_longer('max_temp':'avg_temp', 
                          names_to = "stat", 
                          values_to = "value") %>%
  ggplot(aes(value, fill = stat)) +
    geom_histogram(binwidth = 0.1, 
                   alpha = 0.5, 
                   position = "identity") +
    scale_fill_discrete(labels = c("Average", "Maximum", "Minimum")) +
    labs(x = "Temperature (c)", 
         y = "Observations", 
         fill = "Daily Temperature",
         title = "Distribution of Temperatures at 12 Meters") +
    theme(legend.position = c(0.85, 0.8))

```


An important factor in time series analysis is the continuity of time.  Below, I review the data for missing dates.    
```{r modeling- creating time series}

# QUESTION!!! Does the ts frame need to include every date or can it be missing dates?
FullSeq <- seq.Date(from = min(avgTemp12m$date), to = max(avgTemp12m$date), by = 1)
MissingDate <- FullSeq[!FullSeq %in% avgTemp12m$date]
str(MissingDate)

# Need to use MICE package?
# Use statsNA from imputeTS package?

# Below, genearting time sereies, plotting, and QQ plot.
timeseries <- ts(avgTemp12m$avg_temp)
plot(timeseries)

# QQ plot.  
qqnorm(timeseries, main = "QQ-plot")
qqline(timeseries, col = "red")
```




Using ....Autoregressive Integrated Moving Average (ARIMA)
```{r time series model 1}

# Creating ts analysis



# QUESTION!!! confirm 365 is correct.
ts_diff <- diff(timeseries, lag = 365)
ts.plot(ts_diff)

# Below, arima estimates white noise of the ts data.  The model matches the mean and var.
# ARIMA = autoregressive integrated moving average
white_noise <- arima(timeseries, order = c(0,0,0))
mean(timeseries)
var(timeseries)

# Below, we calculate the correlation at 1 lag to see if one observation is dependent on another.
# Define x_t0 as x[-1]
timeseries_t0 <- timeseries[-1]
# Define x_t1 as x[-n]
n <- length(timeseries)
timeseries_t1 <- timeseries[-n]
# Confirm that x_t0 and x_t1 are (x[t], x[t-1]) pairs  
head(cbind(timeseries_t0, timeseries_t1))
# Plot x_t0 and x_t1
plot(timeseries_t0, timeseries_t1)
# View the correlation between x_t0 and x_t1
cor(timeseries_t0, timeseries_t1)
# Confirm that difference factor is (n-1)/n
cor(timeseries_t1, timeseries_t0) * (n-1)/n

# Below, we use autocorrelation function (acf) with lag.max to calculate correlations at various lags.  High correlation over multiple lags shows high persistence.
acf(timeseries, lag.max = 50, plot = FALSE)
acf(timeseries, lag.max = 50)
pacf(timeseries, lag.max = 50)

# Below, ploting time sereies and de-trended time series.
par(mfrow = c(2,1))
plot(timeseries)
plot(diff(log(timeseries)))

# Use sarima() from astsa package for multi-plot of ts model.
```


